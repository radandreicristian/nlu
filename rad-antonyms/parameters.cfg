[paths]

# Path to the original word vectors
VEC_PATH = lang/vectors/ro_ft_300.vec

# Path to the root of the folder containing word vectors
VEC_ROOT_PATH = lang/vectors

# Vocabulary paths

# Path to the language vocabulary (extracted from the vectors)
VOCAB_PATH = lang/vocab.txt

# Path to the vocabulary that contains only the words found in the datasets with diacritics
VOCAB_PATH_DATASET_DIAC = lang/vocab_small_diac.txt

# Path to the vocabulary that contains only the words found in the  dataset without diacritics
VOCAB_PATH_DATASET_NODIAC = lang/vocab_small_nodiac.txt

# Path to the root folder that contains the linguistic constraints (ants/syns)
CONSTRAINTS_ROOT_PATH = lang/constraints

# Path to the counterfit vectors
CF_VEC_PATH = lang/vectors/ro_ft_300_counterfit_.vec

# Path to the VSP pairs in case we decide to save them locally to avoid computationally intensive op
# No.
VSP_PAIRS_PATH = lang/constraints/vsp_pairs_vocab.txt

# Path to the root of datasets
DATASET_DIAC_PATH = datasets/cu_diacritice/v2
DATASET_NODIAC_PATH = datasets/fara_diacritice

# Path to dataset antonym pairs
DATASET_ANTONYMS_PATH = lang/dataset_antonyms.txt
DATASET_SYNONYMS_PATH = lang/dataset_synonyms.txt

# Paths to RASA specific files
SCRIPT_PATH = verify.bat
RASA_CONFIG_PATH = config.yml

# Paths to the RASA reports
INTENT_REPORT_PATH = results/intent_report.json
INTENT_ERRORS_PATH = results/intent_errors.json
SLOT_REPORT_PATH = results/CRFEntityExtractor_report.json
SLOT_ERRORS_PATH = results/CRFEntityExtractor_errors.json
CONFUSION_MATRIX_PATH = results/confmat.png
HISTOGRAM_PATH = results/hist.png

# Paths to the RASA merged report files (For xvalidation, etc.)
MERGED_REPORTS_ROOT = results/merged_reports
MERGED_INTENT_REPORT_PATH = results/merged_reports/intent_report_merged.txt
MERGED_INTENT_ERRORS_PATH = results/merged_reports/intent_errors_merged.txt
MERGED_SLOT_REPORT_PATH = results/merged_reports/slot_report_merged.txt
MERGED_SLOT_ERRORS_PATH = results/merged_reports/slot_errors_merged.txt
MERGED_MATRICES_PATH = results/merged_reports/confusion_matrices
MERGED_HISTOGRAMS_PATH = results/merged_reports/histograms
ARCHIEVES_PATH = results/analysis_archives/


# Path to the output folder where reports should be saved, if SAVE_TO equals 'Local'
QUANTITATIVE_RESULTS_PATH = results/merged_reports/quantitative_reports

[settings]

# Whether we load the vocabulary with or without diacritics. Either True or False.
DIACRITICS = True

# Whether we load the whole vocabulary or just the words in our datasets. Either 'all' or 'small'.
VOCABULARY = all

# Which components are used for Counterfitting. MODE is a subset of [syn, ant, vsp]
MODE = [ant, syn]

# Indicates which parts of speech are included for linguistic constraints. POS is a subset of [noun, verb, adjective, adverb]
POS = [noun, verb, adjective, adverb]

# The name of the base spacy language model
# TODO: Figure out how I generated this model because I cannot reproduce it. Must contain POS Tagger / Parser for verb inference.
BASE_LANGAUGE = ro_ft_300_og_all

# ISO code of the base language
LANGUAGE_CODE = ro

# Whether to save the quantitative analysis reports locally (=Local), or to the cloud (=Cloud)
SAVE_TO = Local

# Path to the JSON containing the Google sheets secret
SECRET_PATH = thesis_secret.json

# Name of the spreadsheet where the results should be put, if SAVE_TO equals 'Cloud'
SPREADSHEET_NAME = Counterfitting-Diac

[hyperparameters]
# RASA Pipelien Hyperparameters (KStratifiedSampling)
SPLITS = 1
SAMPLE_PERCENT = 0.9

# Counterfitting loss funciton hyperparameters
K1 = 1
K2 = 0.1
K3 = 0.1

# Ideal antonyms distance (1 - orthogonality, 2 - anti-parallelism)
DELTA = 2

# Ideal synonym distance (0 - max similarity / min distance)
GAMMA = 0.0

# Max difference for VSP pair
RHO = 0.2

# Counterfitting gradient descent epochs
GRADIENT_EPOCHS = 20

# Minimum difference of cos distances for pairs to be considered "modified"
EPSILON = 0.05

[components]

# If we want to augment word vectors
AUGMENTER = True