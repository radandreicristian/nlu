[paths]

# Original vectors path
VEC_PATH = lang/vectors/ro_ft_300.vec
VEC_ROOT_PATH = lang/vectors

# Vocabulary paths

# Contains the language of the entire vocabulary (extracted from the vectors)
VOCAB_PATH = lang/vocab.txt

# Contains only the words found in the datasets with diacritics
VOCAB_PATH_DATASET_DIAC = lang/vocab_small_diac.txt

# Contains only the words found in the dataset without diacritics
VOCAB_PATH_DATASET_NODIAC = lang/vocab_small_nodiac.txt

CONSTRAINTS_ROOT_PATH = lang/constraints

# Path to the counterfit vector resulting path
# TODO: Generate the name accoringly based on the parameters
CF_VEC_PATH = lang/vectors/ro_ft_300_allpos_rwn_ant_syn_augpairs.vec

# Path to the VSP pairs in case we decide to save them locally to avoid computationally intensive op
VSP_PAIRS_PATH = lang/constraints/vsp_pairs_vocab.txt

# Path to the root of datasets
DATASET_DIAC_PATH = datasets/cu_diacritice
DATASET_NODIAC_PATH = datasets/fara_diacritice

# Path to dataset antonym pairs
DATASET_ANTONYMS_PATH = lang/dataset_antonyms.txt
DATASET_SYNONYMS_PATH = lang/dataset_synonyms.txt

# RASA files paths
SCRIPT_PATH = verify.bat
RASA_CONFIG_PATH = config.yml

# RASA report files paths
INTENT_REPORT_PATH = results/intent_report.json
INTENT_ERRORS_PATH = results/intent_errors.json
SLOT_REPORT_PATH = results/CRFEntityExtractor_report.json
SLOT_ERRORS_PATH = results/CRFEntityExtractor_errors.json
CONFUSION_MATRIX_PATH = results/confmat.png

# RASA merged report files paths
MERGED_REPORTS_ROOT = results/merged_reports
MERGED_INTENT_REPORT_PATH = results/merged_reports/intent_report_merged.txt
MERGED_INTENT_ERRORS_PATH = results/merged_reports/intent_errors_merged.txt
MERGED_SLOT_REPORT_PATH = results/merged_reports/slot_report_merged.txt
MERGED_SLOT_ERRORS_PATH = results/merged_reports/slot_errors_merged.txt
MERGED_MATRICES_PATH = results/merged_reports/confusion_matrices

ARCHIEVES_PATH = results/analysis_archives/

[settings]

# Whether we load the vocabulary with or without diacritics. Either True or False.
DIACRITICS = True

# Whether we load the whole vocabulary or just the words in our datasets. Either 'all' or 'small'.
VOCABULARY = all

# Which components are used for Counterfitting. MODE is a subset of [syn, ant, vsp]
MODE = [ant, syn]

# Indicates which parts of speech are included for linguistic constraints. POS is a subset of [noun, verb, adjective, adverb]
POS = [noun, verb, adjective, adverb]

# The name of the base spacy language model
# TODO: Remember how I generated this because I cannot reproduce it. Must contain POS Tagger / Parser for verb inference.
BASE_LANGAUGE = ro_ft_300_og_all

LANGUAGE_CODE = ro

GOOGLE_SPREADSHEET_NAME = Counterfitting-Diac

[hyperparameters]

# RASA Pipelien Hyperparameters (KStratifiedSampling)
splits = 5
sample_percent = 0.9

# Counterfitting loss funciton hyperparameters
hyper_k1 = 1
hyper_k2 = 0.1
hyper_k3 = 0.1

# Ideal antonyms distance
delta = 1.5

# Ideal synonym distance
gamma = 0.0

# Max difference for VSP pair
rho = 0.2

# Counterfitting SGD steps
sgd_iters = 20

# Minimum difference of cos distances for pairs to be considered "modified"
epsilon = 0.05